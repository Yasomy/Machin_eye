import cv2
import time
import torch
import numpy as np
from ultralytics import YOLO
import sort  #(pip install filterpy lap)
import random


class ObjectDetectionStream:
    def __init__(self, stream_url, input_size=1920):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ –¥–ª—è –≤–∏–¥–µ–æ–ø–æ—Ç–æ–∫–∞ —Å —Ç—Ä–µ–∫–∏–Ω–≥–æ–º.
        :param stream_url: URL –≤–∏–¥–µ–æ–ø–æ—Ç–æ–∫–∞
        :param input_size: —Ä–∞–∑–º–µ—Ä –∫–∞–¥—Ä–∞ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏
        """
        self.stream_url = stream_url
        self.input_size = input_size
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"üîπ –ò—Å–ø–æ–ª—å–∑—É–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device.upper()}")
        self.model = self.load_model()
        # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ –∫–ª–∞—Å—Å–æ–≤
        self.CLASS_NAMES_DICT = self.model.model.names

    def load_model(self):
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å YOLO –∏ –ø–µ—Ä–µ–≤–æ–¥–∏—Ç –µ–µ –Ω–∞ –Ω—É–∂–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ.
        """
        model = YOLO("best_x3.pt").to(self.device)
        # –ü—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –º–æ–∂–Ω–æ –≤—ã–ø–æ–ª–Ω–∏—Ç—å fuse() –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è:
        model.fuse()
        return model

    def predict(self, frame):
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ –¥–∞–Ω–Ω–æ–º –∫–∞–¥—Ä–µ.
        :param frame: –∫–∞–¥—Ä –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (—Ä–∞–∑–º–µ—Ä –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å input_size x input_size)
        :return: —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–µ—Ç–µ–∫—Ü–∏–∏
        """
        results = self.model(frame)
        return results

    def get_results(self, results, original_w, original_h):
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–µ—Ç–µ–∫—Ü–∏–∏ –¥–ª—è –∫–ª–∞—Å—Å–æ–≤ person (0) –∏ transport (2)
        –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –æ–±—Ä–∞—Ç–Ω–æ –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—é.
        
        :param results: —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–æ–¥–µ–ª–∏
        :param original_w: –∏—Å—Ö–æ–¥–Ω–∞—è —à–∏—Ä–∏–Ω–∞ –∫–∞–¥—Ä–∞
        :param original_h: –∏—Å—Ö–æ–¥–Ω–∞—è –≤—ã—Å–æ—Ç–∞ –∫–∞–¥—Ä–∞
        :return: (detections, person_count, transport_count)
          detections ‚Äì numpy-–º–∞—Å—Å–∏–≤, –≥–¥–µ –∫–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞ –∏–º–µ–µ—Ç –≤–∏–¥:
                       [x1, y1, x2, y2, confidence, class_id]
        """
        detections = []
        person_count = 0
        transport_count = 0
        # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—é
        scale_x = original_w / self.input_size
        scale_y = original_h / self.input_size

        for box in results[0].boxes:
            cls = int(box.cls[0])
            if cls in [0, 2]:
                bbox = box.xyxy.cpu().numpy()  # —Ñ–æ—Ä–º–∞—Ç [[x1, y1, x2, y2]]
                conf = box.conf.cpu().numpy()[0]
                x1 = bbox[0][0] * scale_x
                y1 = bbox[0][1] * scale_y
                x2 = bbox[0][2] * scale_x
                y2 = bbox[0][3] * scale_y
                detections.append([x1, y1, x2, y2, conf, cls])
                if cls == 0:
                    person_count += 1
                elif cls == 2:
                    transport_count += 1
        detections = np.array(detections) if detections else np.empty((0, 6))
        return detections, person_count, transport_count

    def draw_tracking_boxes(self, frame, tracked_objects):
        """
        –û—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ—Ç —Ç—Ä–µ–∫–∏–Ω–≥–æ–≤—ã–µ –±–æ–∫—Å—ã –¥–ª—è –æ–±—ä–µ–∫—Ç–æ–≤ –∫–ª–∞—Å—Å–∞ person —Å –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–º (ID).
        :param frame: –∏—Å—Ö–æ–¥–Ω—ã–π –∫–∞–¥—Ä
        :param tracked_objects: numpy-–º–∞—Å—Å–∏–≤ (N, 5): [x1, y1, x2, y2, track_id]
        :return: –∫–∞–¥—Ä —Å –æ—Ç—Ä–∏—Å–æ–≤–∞–Ω–Ω—ã–º–∏ –±–æ–∫c–∞–º–∏
        """
        for obj in tracked_objects:
            x1, y1, x2, y2, track_id = obj
            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 2)
            cv2.putText(frame, f"ID: {int(track_id)}", (int(x1), int(y1)-10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)
        return frame

    def draw_transport_boxes(self, frame, detections):
        """
        –û—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ—Ç –±–æ–∫—Å—ã –¥–ª—è –æ–±—ä–µ–∫—Ç–æ–≤ –∫–ª–∞—Å—Å–∞ transport.
        :param frame: –∏—Å—Ö–æ–¥–Ω—ã–π –∫–∞–¥—Ä
        :param detections: –º–∞—Å—Å–∏–≤ –¥–µ—Ç–µ–∫—Ü–∏–π [x1, y1, x2, y2, conf, class_id]
        :return: –∫–∞–¥—Ä —Å –æ—Ç—Ä–∏—Å–æ–≤–∞–Ω–Ω—ã–º–∏ –±–æ–∫c–∞–º–∏ –¥–ª—è —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞
        """
        for det in detections:
            x1, y1, x2, y2, conf, cls = det
            if int(cls) == 2:
                cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)
                cv2.putText(frame, f"Transport: {conf:.2f}", (int(x1), int(y1)-10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)
        return frame

    def __call__(self):
        """
        –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ–ø–æ—Ç–æ–∫–∞.
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ, —Ç—Ä–µ–∫–∏–Ω–≥ –¥–ª—è –æ–±—ä–µ–∫—Ç–æ–≤ –∫–ª–∞—Å—Å–∞ person,
        –æ—Ç—Ä–∏—Å–æ–≤–∫—É —Ç—Ä–µ–∫–∏–Ω–≥–æ–≤—ã—Ö –±–æ–∫—Å–æ–≤ –∏ –±–æ–∫—Å–æ–≤ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞, –≤—ã–≤–æ–¥ FPS –∏ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–æ—Ö—Ä–∞–Ω—è—Ç—å —Å–∫—Ä–∏–Ω—à–æ—Ç—ã.
        """
        cap = cv2.VideoCapture(self.stream_url)
        if not cap.isOpened():
            print("‚ùå –û—à–∏–±–∫–∞: OpenCV –Ω–µ –º–æ–∂–µ—Ç –æ—Ç–∫—Ä—ã—Ç—å –ø–æ—Ç–æ–∫!")
            return

        original_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        original_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        if original_w == 0 or original_h == 0:
            print("‚ùå –û—à–∏–±–∫–∞: –Ω–µ–≤–µ—Ä–Ω—ã–π —Ä–∞–∑–º–µ—Ä –≤–∏–¥–µ–æ!")
            return

        num = 1  # –Ω–æ–º–µ—Ä –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤
        prev_time = time.time()
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º SORT —Ç—Ä–µ–∫–µ—Ä –¥–ª—è –æ–±—ä–µ–∫—Ç–æ–≤ –∫–ª–∞—Å—Å–∞ person
        tracker = sort.Sort(max_age=500, min_hits=15, iou_threshold=0.15)

        while True:
            ret, frame = cap.read()
            if not ret or frame is None:
                print("‚ùå –û—à–∏–±–∫–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–∞–¥—Ä.")
                break

            # –ò–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä –¥–ª—è –ø–æ–¥–∞—á–∏ –≤ –º–æ–¥–µ–ª—å
            resized_frame = cv2.resize(frame, (self.input_size, self.input_size))
            results = self.predict(resized_frame)
            # –ü–æ–ª—É—á–∞–µ–º –¥–µ—Ç–µ–∫—Ü–∏–∏ –¥–ª—è –∫–ª–∞—Å—Å–æ–≤ person –∏ transport
            detections, person_count, transport_count = self.get_results(results, original_w, original_h)

            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–µ—Ç–µ–∫—Ü–∏–π –¥–ª—è —Ç—Ä–µ–∫–∏–Ω–≥–∞ (—Ç–æ–ª—å–∫–æ –æ–±—ä–µ–∫—Ç—ã –∫–ª–∞—Å—Å–∞ person)
            person_detections = []
            for det in detections:
                if int(det[5]) == 0:
                    # –ö–∞–∂–¥–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è: [x1, y1, x2, y2, confidence]
                    person_detections.append([det[0], det[1], det[2], det[3], det[4]])
            if person_detections:
                person_detections_np = np.array(person_detections)
            else:
                person_detections_np = np.empty((0, 5))

            # –û–±–Ω–æ–≤–ª—è–µ–º —Ç—Ä–µ–∫–∏–Ω–≥
            tracked_objects = tracker.update(person_detections_np)

            # –û—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ–º —Ç—Ä–µ–∫–∏–Ω–≥–æ–≤—ã–µ –±–æ–∫—Å—ã –¥–ª—è persons
            frame = self.draw_tracking_boxes(frame, tracked_objects)
            # –û—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ–º –±–æ–∫—Å—ã –¥–ª—è —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞
            frame = self.draw_transport_boxes(frame, detections)

            # –†–∞—Å—á–µ—Ç FPS
            curr_time = time.time()
            fps = 1 / (curr_time - prev_time) if (curr_time - prev_time) > 0 else 0
            prev_time = curr_time

            cv2.putText(frame, f"FPS: {int(fps)}", (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            cv2.putText(frame, f"People: {person_count}", (20, 80), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)
            cv2.putText(frame, f"Transport: {transport_count}", (20, 120), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 255), 2)

            cv2.imshow("YOLO Stream with Tracking (GPU)", frame)

            key = cv2.waitKey(1)
            if key == ord("q"):
                break
            elif key == ord("s"):
                cv2.imwrite(f'images/img{num}.png', frame)
                print("–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ!")
                num += 1

        cap.release()
        cv2.destroyAllWindows()


if __name__ == '__main__':
    stream_url = ("http://46.191.199.34/001-999-4-348/tracks-v1/index.fmp4.m3u8?token=05a520d05dd94e1d857ac5747a8d91b9")
    detector = ObjectDetectionStream(stream_url)
    detector()
